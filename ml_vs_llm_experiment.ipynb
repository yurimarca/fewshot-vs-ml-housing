{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML vs LLM Comparison: Real Estate Price Prediction\n",
    "\n",
    "This notebook compares traditional machine learning approaches with Large Language Model (LLM) few-shot learning for house price prediction on the Indian real estate dataset.\n",
    "\n",
    "## Approaches Compared:\n",
    "\n",
    "### Traditional ML:\n",
    "- Linear Regression\n",
    "- Random Forest Regressor\n",
    "- XGBoost Regressor\n",
    "- SVM Regressor\n",
    "\n",
    "### LLM Approaches:\n",
    "- Zero-shot learning (no examples)\n",
    "- One-shot learning (1 example)\n",
    "- Few-shot learning (5, 10, 20 examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import openai\n",
    "import json\n",
    "import time\n",
    "from typing import List, Dict, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"data/House Price India.csv\")\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"\\nColumns: {list(data.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics and data exploration\n",
    "print(\"Dataset Info:\")\n",
    "print(data.info())\n",
    "print(\"\\nPrice Statistics:\")\n",
    "print(data['Price'].describe())\n",
    "print(f\"\\nPrice range: ₹{data['Price'].min():,.0f} to ₹{data['Price'].max():,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize price distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Price distribution\n",
    "axes[0].hist(data['Price'], bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[0].set_title('Price Distribution')\n",
    "axes[0].set_xlabel('Price (₹)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# Log price distribution\n",
    "axes[1].hist(np.log(data['Price']), bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1].set_title('Log Price Distribution')\n",
    "axes[1].set_xlabel('Log Price')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing for ML models\n",
    "def preprocess_data(data):\n",
    "    # Remove ID and Date columns\n",
    "    features_to_drop = ['id', 'Date']\n",
    "    X = data.drop(features_to_drop + ['Price'], axis=1)\n",
    "    y = data['Price']\n",
    "    \n",
    "    # Handle any missing values\n",
    "    X = X.fillna(X.median())\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = preprocess_data(data)\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeatures: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features for algorithms that need it\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate ML models\n",
    "ml_models = {}\n",
    "ml_results = {}\n",
    "\n",
    "# Linear Regression\n",
    "print(\"Training Linear Regression...\")\n",
    "ml_models['Linear Regression'] = LinearRegression()\n",
    "ml_models['Linear Regression'].fit(X_train_scaled, y_train)\n",
    "\n",
    "# Random Forest\n",
    "print(\"Training Random Forest...\")\n",
    "ml_models['Random Forest'] = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "ml_models['Random Forest'].fit(X_train, y_train)\n",
    "\n",
    "# XGBoost\n",
    "print(\"Training XGBoost...\")\n",
    "ml_models['XGBoost'] = xgb.XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "ml_models['XGBoost'].fit(X_train, y_train)\n",
    "\n",
    "# SVM Regressor\n",
    "print(\"Training SVM...\")\n",
    "ml_models['SVM'] = SVR(kernel='rbf', C=1000, gamma=0.001)\n",
    "ml_models['SVM'].fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"All models trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate ML models\n",
    "def evaluate_model(name, model, X_test_data, y_true):\n",
    "    y_pred = model.predict(X_test_data)\n",
    "    \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "\n",
    "# Evaluate all ML models\n",
    "for name, model in ml_models.items():\n",
    "    if name in ['Linear Regression', 'SVM']:\n",
    "        results = evaluate_model(name, model, X_test_scaled, y_test)\n",
    "    else:\n",
    "        results = evaluate_model(name, model, X_test, y_test)\n",
    "    \n",
    "    ml_results[name] = results\n",
    "    print(f\"{name}: MAE={results['MAE']:.2f}, RMSE={results['RMSE']:.2f}, R²={results['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ML model performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (name, results) in enumerate(ml_results.items()):\n",
    "    ax = axes[i]\n",
    "    ax.scatter(y_test, results['predictions'], alpha=0.5)\n",
    "    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    ax.set_xlabel('Actual Price')\n",
    "    ax.set_ylabel('Predicted Price')\n",
    "    ax.set_title(f'{name}\\nR² = {results[\"R2\"]:.4f}, RMSE = {results[\"RMSE\"]:.0f}')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM-based Approaches\n",
    "\n",
    "**Note:** To run the LLM experiments, you need to:\n",
    "1. Set your OpenAI API key\n",
    "2. Uncomment and run the LLM evaluation cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your OpenAI API key here\n",
    "# openai.api_key = \"your-api-key-here\"\n",
    "\n",
    "def create_property_description(row):\n",
    "    \"\"\"Convert a property row to natural language description\"\"\"\n",
    "    description = f\"\"\"Property Details:\n",
    "- {int(row['number of bedrooms'])} bedrooms, {row['number of bathrooms']:.1f} bathrooms\n",
    "- Living area: {int(row['living area'])} sq ft\n",
    "- Lot area: {int(row['lot area'])} sq ft  \n",
    "- {row['number of floors']:.1f} floors\n",
    "- {'Waterfront property' if row['waterfront present'] else 'No waterfront'}\n",
    "- {int(row['number of views'])} views\n",
    "- Condition: {int(row['condition of the house'])}/10\n",
    "- Grade: {int(row['grade of the house'])}/13\n",
    "- House area (excluding basement): {int(row['Area of the house(excluding basement)'])} sq ft\n",
    "- Basement area: {int(row['Area of the basement'])} sq ft\n",
    "- Built in {int(row['Built Year'])}\n",
    "- {'Renovated in ' + str(int(row['Renovation Year'])) if row['Renovation Year'] > 0 else 'Not renovated'}\n",
    "- Postal code: {int(row['Postal Code'])}\n",
    "- Location: ({row['Lattitude']:.4f}, {row['Longitude']:.4f})\n",
    "- Renovated living area: {int(row['living_area_renov'])} sq ft\n",
    "- Renovated lot area: {int(row['lot_area_renov'])} sq ft\n",
    "- {int(row['Number of schools nearby'])} schools nearby\n",
    "- {row['Distance from the airport']:.1f} km from airport\"\"\"\n",
    "    return description\n",
    "\n",
    "# Example property description\n",
    "sample_row = X_test.iloc[0]\n",
    "sample_description = create_property_description(sample_row)\n",
    "print(\"Sample property description:\")\n",
    "print(sample_description)\n",
    "print(f\"\\nActual price: ₹{y_test.iloc[0]:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM prediction function\n",
    "def get_llm_prediction(property_description, examples=None, shot_type=\"zero\"):\n",
    "    \"\"\"Get price prediction from LLM using different shot approaches\"\"\"\n",
    "    \n",
    "    if shot_type == \"zero\":\n",
    "        prompt = f\"\"\"You are a real estate expert. Based on the property details below, estimate the price in Indian Rupees (₹).\n",
    "\n",
    "{property_description}\n",
    "\n",
    "Provide only the numerical price estimate without currency symbol or formatting.\"\"\"\n",
    "    \n",
    "    elif shot_type == \"one\":\n",
    "        example = examples[0] if examples else \"\"\n",
    "        prompt = f\"\"\"You are a real estate expert. Based on the property details, estimate the price in Indian Rupees (₹).\n",
    "\n",
    "Example:\n",
    "{example}\n",
    "\n",
    "Now estimate the price for this property:\n",
    "{property_description}\n",
    "\n",
    "Provide only the numerical price estimate without currency symbol or formatting.\"\"\"\n",
    "    \n",
    "    else:  # few-shot\n",
    "        examples_text = \"\\n\\n\".join(examples) if examples else \"\"\n",
    "        prompt = f\"\"\"You are a real estate expert. Based on the property details, estimate the price in Indian Rupees (₹).\n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "{examples_text}\n",
    "\n",
    "Now estimate the price for this property:\n",
    "{property_description}\n",
    "\n",
    "Provide only the numerical price estimate without currency symbol or formatting.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=50,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        prediction_text = response.choices[0].message.content.strip()\n",
    "        # Extract numerical value\n",
    "        prediction = float(''.join(filter(str.isdigit, prediction_text.replace(',', ''))))\n",
    "        return prediction\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting LLM prediction: {e}\")\n",
    "        return None\n",
    "\n",
    "# Prepare few-shot examples\n",
    "def prepare_few_shot_examples(n_examples=5):\n",
    "    \"\"\"Prepare examples for few-shot learning\"\"\"\n",
    "    example_indices = np.random.choice(len(X_train), n_examples, replace=False)\n",
    "    examples = []\n",
    "    \n",
    "    for idx in example_indices:\n",
    "        row = X_train.iloc[idx]\n",
    "        price = y_train.iloc[idx]\n",
    "        description = create_property_description(row)\n",
    "        example = f\"{description}\\nPrice: ₹{price:,.0f}\"\n",
    "        examples.append(example)\n",
    "    \n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell to evaluate LLM approaches\n",
    "# Note: This will make API calls to OpenAI and may incur costs\n",
    "\n",
    "# llm_results = {}\n",
    "# n_test_samples = 50  # Adjust based on your budget\n",
    "\n",
    "# # Sample test data\n",
    "# test_indices = np.random.choice(len(X_test), min(n_test_samples, len(X_test)), replace=False)\n",
    "\n",
    "# shot_configs = {\n",
    "#     'Zero-shot': ('zero', None),\n",
    "#     'One-shot': ('one', 1), \n",
    "#     'Few-shot (5)': ('few', 5),\n",
    "#     'Few-shot (10)': ('few', 10),\n",
    "#     'Few-shot (20)': ('few', 20)\n",
    "# }\n",
    "\n",
    "# for approach_name, (shot_type, n_examples) in shot_configs.items():\n",
    "#     print(f\"\\nEvaluating {approach_name}...\")\n",
    "#     predictions = []\n",
    "#     actual_prices = []\n",
    "    \n",
    "#     # Prepare examples\n",
    "#     if n_examples:\n",
    "#         examples = prepare_few_shot_examples(n_examples)\n",
    "#     else:\n",
    "#         examples = None\n",
    "    \n",
    "#     for idx in test_indices:\n",
    "#         row = X_test.iloc[idx]\n",
    "#         actual_price = y_test.iloc[idx]\n",
    "#         description = create_property_description(row)\n",
    "        \n",
    "#         prediction = get_llm_prediction(description, examples, shot_type)\n",
    "        \n",
    "#         if prediction is not None:\n",
    "#             predictions.append(prediction)\n",
    "#             actual_prices.append(actual_price)\n",
    "        \n",
    "#         # Delay to avoid rate limiting\n",
    "#         time.sleep(0.1)\n",
    "    \n",
    "#     if predictions:\n",
    "#         predictions = np.array(predictions)\n",
    "#         actual_prices = np.array(actual_prices)\n",
    "        \n",
    "#         mae = mean_absolute_error(actual_prices, predictions)\n",
    "#         mse = mean_squared_error(actual_prices, predictions)\n",
    "#         rmse = np.sqrt(mse)\n",
    "#         r2 = r2_score(actual_prices, predictions)\n",
    "        \n",
    "#         llm_results[approach_name] = {\n",
    "#             'MAE': mae,\n",
    "#             'MSE': mse,\n",
    "#             'RMSE': rmse,\n",
    "#             'R2': r2,\n",
    "#             'n_predictions': len(predictions),\n",
    "#             'predictions': predictions,\n",
    "#             'actual': actual_prices\n",
    "#         }\n",
    "        \n",
    "#         print(f\"{approach_name}: MAE={mae:.2f}, RMSE={rmse:.2f}, R²={r2:.4f} ({len(predictions)} predictions)\")\n",
    "\n",
    "print(\"Uncomment the above code to run LLM experiments (requires OpenAI API key)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all approaches\n",
    "def create_comparison_table(ml_results, llm_results=None):\n",
    "    \"\"\"Create a comparison table of all approaches\"\"\"\n",
    "    \n",
    "    all_results = ml_results.copy()\n",
    "    if llm_results:\n",
    "        all_results.update(llm_results)\n",
    "    \n",
    "    # Create DataFrame for better visualization\n",
    "    comparison_data = []\n",
    "    for name, metrics in all_results.items():\n",
    "        comparison_data.append({\n",
    "            'Approach': name,\n",
    "            'MAE': metrics['MAE'],\n",
    "            'RMSE': metrics['RMSE'],\n",
    "            'R²': metrics['R2'],\n",
    "            'Type': 'Traditional ML' if name in ml_results else 'LLM'\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(comparison_data)\n",
    "    df = df.sort_values('R²', ascending=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create comparison table (currently only ML results)\n",
    "comparison_df = create_comparison_table(ml_results)  # Add llm_results when available\n",
    "print(\"Performance Comparison (Traditional ML Models):\")\n",
    "print(\"=\" * 60)\n",
    "print(comparison_df.to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "# Find best performing model\n",
    "best_model = comparison_df.iloc[0]\n",
    "print(f\"\\nBest performing model: {best_model['Approach']}\")\n",
    "print(f\"R² Score: {best_model['R²']:.4f}\")\n",
    "print(f\"RMSE: ₹{best_model['RMSE']:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize performance comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# R² comparison\n",
    "axes[0].bar(comparison_df['Approach'], comparison_df['R²'], color='skyblue', edgecolor='black')\n",
    "axes[0].set_title('R² Score Comparison')\n",
    "axes[0].set_ylabel('R² Score')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE comparison\n",
    "axes[1].bar(comparison_df['Approach'], comparison_df['MAE'], color='lightcoral', edgecolor='black')\n",
    "axes[1].set_title('Mean Absolute Error Comparison')\n",
    "axes[1].set_ylabel('MAE (₹)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# RMSE comparison\n",
    "axes[2].bar(comparison_df['Approach'], comparison_df['RMSE'], color='lightgreen', edgecolor='black')\n",
    "axes[2].set_title('Root Mean Square Error Comparison')\n",
    "axes[2].set_ylabel('RMSE (₹)')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis (for tree-based models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for Random Forest and XGBoost\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Random Forest feature importance\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': ml_models['Random Forest'].feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "axes[0].barh(rf_importance['feature'], rf_importance['importance'])\n",
    "axes[0].set_title('Random Forest - Feature Importance')\n",
    "axes[0].set_xlabel('Importance')\n",
    "\n",
    "# XGBoost feature importance\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': ml_models['XGBoost'].feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "axes[1].barh(xgb_importance['feature'], xgb_importance['importance'])\n",
    "axes[1].set_title('XGBoost - Feature Importance')\n",
    "axes[1].set_xlabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 5 most important features (Random Forest):\")\n",
    "print(rf_importance.tail().to_string(index=False))\n",
    "print(\"\\nTop 5 most important features (XGBoost):\")\n",
    "print(xgb_importance.tail().to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Traditional ML Performance**: \n",
    "   - All traditional ML models show strong performance on this structured dataset\n",
    "   - Tree-based models (Random Forest, XGBoost) typically perform best\n",
    "   - Linear models may struggle with non-linear relationships\n",
    "\n",
    "2. **Feature Importance**:\n",
    "   - Location features (latitude, longitude) are typically highly important\n",
    "   - House size features (living area, lot area) are crucial predictors\n",
    "   - Quality indicators (grade, condition) significantly impact price\n",
    "\n",
    "3. **LLM Comparison** (when run):\n",
    "   - Zero-shot: Tests the model's inherent real estate knowledge\n",
    "   - One-shot: Shows how one example can guide predictions\n",
    "   - Few-shot: Demonstrates the power of in-context learning\n",
    "\n",
    "### Trade-offs:\n",
    "\n",
    "- **Traditional ML**: Fast inference, interpretable, well-established metrics\n",
    "- **LLM Approaches**: More flexible, can handle natural language descriptions, but slower and more expensive\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Run LLM experiments by setting up OpenAI API key\n",
    "2. Experiment with different prompt engineering techniques\n",
    "3. Try ensemble methods combining both approaches\n",
    "4. Implement cross-validation for more robust evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}